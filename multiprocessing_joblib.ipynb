{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92ae225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50030f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_square(start, end):\n",
    "    result = 0\n",
    "    for i in range(start, end):\n",
    "        result += i ** 2\n",
    "        result += math.factorial(i % 10)  \n",
    "        result += int(math.sin(i) * 1000000)  \n",
    "        result += int(math.sqrt(i) * 1000)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5c38c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Process Result: 333333329004091102437280\n"
     ]
    }
   ],
   "source": [
    "results = compute_square(0, 100000000)\n",
    "print(\"Single Process Result:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "426be21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core count: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"core count:\", joblib.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f224f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel Process Result: 333333329004091102437280\n"
     ]
    }
   ],
   "source": [
    "n_jobs = joblib.cpu_count()\n",
    "chunk_size = 100000000 // n_jobs\n",
    "ranges = [(i * chunk_size, (i + 1) * chunk_size if i < n_jobs - 1 else 100000000) for i in range(n_jobs)]\n",
    "\n",
    "results = Parallel(n_jobs=-1)(delayed(compute_square)(start, end) for start, end in ranges) #Burda amacımız chunklarla beraber görev sayısını azaltmak. Parallel fonksiyonun göre sayısı arttıkça overhead artar. Azaltırsak daha iyi performans alırız. Kısaca asıl olay chunk içindeki sayıyı da düzgün bölüştürmek. Böylece her işlemci çekirdeği eşit iş yapar ve overhead azalır.\n",
    "print(\"Parallel Process Result:\", sum(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "036de323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 5306.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for parallel CV: 1.36 seconds\n",
      "Fold 1 Accuracy: 0.8550\n",
      "Fold 2 Accuracy: 0.9100\n",
      "Fold 3 Accuracy: 0.8450\n",
      "Fold 4 Accuracy: 0.8800\n",
      "Fold 5 Accuracy: 0.9100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm \n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=50, n_informative=15, random_state=42)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def train_and_evaluate_fold(train_index, val_index):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=150, random_state=42, n_jobs=1) \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    preds = model.predict(X_val)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, preds)\n",
    "    conf_matrix = confusion_matrix(y_val, preds)\n",
    "    \n",
    "    return {'accuracy': accuracy, 'confusion_matrix': conf_matrix}\n",
    "\n",
    "start = time.time()\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(train_and_evaluate_fold)(train, val) \n",
    "    for train, val in tqdm(kf.split(X), total=kf.get_n_splits())\n",
    ")\n",
    "# Kısaca burda bir chunk oluşturup her fold için paralel işlem yapıyoruz. Oluşturmadan yapamıyoruz tam olarak parallel func u ancak bu şekilde çalışıyor.\n",
    "end = time.time()\n",
    "print(f\"Time taken for parallel CV: {end - start:.2f} seconds\")\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Fold {i+1} Accuracy: {result['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "958bcb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for sequential CV: 1.70 seconds\n",
      "Fold 1 Accuracy: 0.8550\n",
      "Fold 2 Accuracy: 0.9100\n",
      "Fold 3 Accuracy: 0.8450\n",
      "Fold 4 Accuracy: 0.8800\n",
      "Fold 5 Accuracy: 0.9100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from tqdm import tqdm \n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=50, n_informative=15, random_state=42)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def train_and_evaluate_fold(X, y):\n",
    "    start = time.time()\n",
    "    for train, val in tqdm(kf.split(X), total=kf.get_n_splits()):\n",
    "        train_index, val_index = train, val\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        model = RandomForestClassifier(n_estimators=150, random_state=42, n_jobs=1) \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        preds = model.predict(X_val)\n",
    "        \n",
    "        accuracy = accuracy_score(y_val, preds)\n",
    "        conf_matrix = confusion_matrix(y_val, preds)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f\"Time taken for sequential CV: {end - start:.2f} seconds\")\n",
    "    return {'accuracy': accuracy, 'confusion_matrix': conf_matrix}\n",
    "\n",
    "train_and_evaluate_fold(X, y)\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Fold {i+1} Accuracy: {result['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab639f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/.mlenv/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for multiprocessing apply: 0.76 seconds\n"
     ]
    }
   ],
   "source": [
    "from pathos.multiprocessing import Pool, cpu_count\n",
    "import pandas as pd\n",
    "\n",
    "df_mp = pd.DataFrame(np.random.randint(0, 100, size=(1000000, 4)), columns=list('ABCD'))\n",
    "\n",
    "def complex_function(row):\n",
    "    return (row['A'] * row['B']) / (row['C'] + 1) + row['D']\n",
    "\n",
    "def _apply_df_helper(args):\n",
    "    df_chunk, func = args\n",
    "    return df_chunk.apply(func, axis=1)\n",
    "\n",
    "def apply_by_multiprocessing(df, func, **kwargs):\n",
    "    workers = kwargs.pop('workers')\n",
    "    if workers is None:\n",
    "        workers = cpu_count()\n",
    "        \n",
    "    df_split = np.array_split(df, workers)\n",
    "    \n",
    "    start = time.time()\n",
    "    with Pool(processes=workers) as pool:\n",
    "        result = pool.map(_apply_df_helper, [(chunk, func) for chunk in df_split])\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Time taken for multiprocessing apply: {end - start:.2f} seconds\")\n",
    "\n",
    "    return pd.concat(result)\n",
    "\n",
    "mp_num_cores = cpu_count()\n",
    "\n",
    "result_df = apply_by_multiprocessing(df_mp, complex_function, workers=mp_num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f47fd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for sequential apply: 3.87 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result_df = df_mp.apply(complex_function, axis=1)\n",
    "end = time.time()\n",
    "print(f\"Time taken for sequential apply: {end - start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5720e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri boyutu: 500000 satır\n",
      "Kullanılacak çekirdek sayısı: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/.mlenv/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "Process SpawnPoolWorker-12:\n",
      "Process SpawnPoolWorker-11:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-13:\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute '_apply_df_helper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute '_apply_df_helper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-14:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-15:\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute '_apply_df_helper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute '_apply_df_helper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-16:\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute '_apply_df_helper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute '_apply_df_helper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-17:\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute '_apply_df_helper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-19:\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute '_apply_df_helper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute '_apply_df_helper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute '_apply_df_helper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-26:\n",
      "Process SpawnPoolWorker-28:\n",
      "Process SpawnPoolWorker-29:\n",
      "Process SpawnPoolWorker-30:\n",
      "Process SpawnPoolWorker-25:\n",
      "Process SpawnPoolWorker-21:\n",
      "Process SpawnPoolWorker-23:\n",
      "Process SpawnPoolWorker-24:\n",
      "Process SpawnPoolWorker-22:\n",
      "Process SpawnPoolWorker-27:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/queues.py\", line 385, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/connection.py\", line 430, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/connection.py\", line 395, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVeri boyutu: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_SIZE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m satır\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKullanılacak çekirdek sayısı: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmp_num_cores\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m result_df_mp \u001b[38;5;241m=\u001b[39m \u001b[43mapply_by_multiprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomplex_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmp_num_cores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mÇoklu İşlem başarıyla tamamlandı. Sonuç boyutu:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result_df_mp\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m, in \u001b[0;36mapply_by_multiprocessing\u001b[0;34m(df, func, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes\u001b[38;5;241m=\u001b[39mworkers) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 21\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_apply_df_helper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf_split\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# pool.map yerine pool.starmap kullanmak daha temizdir.Eğer birden fazla argümanı (df_chunk ve func) doğrudan iletebiliriz. Ama .map sadece tek argüman alır.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py:375\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/.mlenv/lib/python3.13/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/.mlenv/lib/python3.13/threading.py:659\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    657\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 659\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/anaconda3/envs/.mlenv/lib/python3.13/threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 359\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def _apply_df_helper(df_chunk, func):\n",
    "    return df_chunk.apply(func, axis=1) \n",
    "\n",
    "def complex_function(row):\n",
    "    return (row['A'] * row['B']) / (row['C'] + 1) + row['D']\n",
    "\n",
    "def apply_by_multiprocessing(df, func, **kwargs):\n",
    "    workers = kwargs.pop('workers', cpu_count())\n",
    "    \n",
    "    df_split = np.array_split(df, workers)\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    with Pool(processes=workers) as pool:\n",
    "        result = pool.starmap(_apply_df_helper, [(chunk, func) for chunk in df_split])\n",
    "        # pool.map yerine pool.starmap kullanmak daha temizdir.Eğer birden fazla argümanı (df_chunk ve func) doğrudan iletebiliriz. Ama .map sadece tek argüman alır.\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Çoklu işlem apply süresi: {end - start:.2f} saniye\")\n",
    "    return pd.concat(result)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    DATA_SIZE = 500000\n",
    "    df = pd.DataFrame(np.random.randint(0, 100, size=(DATA_SIZE, 4)), columns=list('ABCD'))\n",
    "    \n",
    "    mp_num_cores = cpu_count()\n",
    "    print(f\"Veri boyutu: {DATA_SIZE} satır\")\n",
    "    print(f\"Kullanılacak çekirdek sayısı: {mp_num_cores}\")\n",
    "    \n",
    "    result_df_mp = apply_by_multiprocessing(df, complex_function, workers=mp_num_cores)\n",
    "    print(\"Çoklu İşlem başarıyla tamamlandı. Sonuç boyutu:\", result_df_mp.shape)\n",
    "    \n",
    "    \n",
    "# Normal .py dosyasında multiprocessing kullanırken dikkat edilmesi gereken bazı önemli noktalar vardır: Bunlarda yukardaki gibi if __name__ == \"__main__\": koruması en kritik olanıdır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adb8995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
